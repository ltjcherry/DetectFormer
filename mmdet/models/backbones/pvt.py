# Copyright (c) OpenMMLab. All rights reserved.
import math

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.checkpoint as cp
from mmcv.cnn import build_conv_layer, build_norm_layer
from mmcv.runner import BaseModule

from ..builder import BACKBONES
from ..utils import ResLayer
from .resnet import Bottleneck as _Bottleneck
from .resnet import ResNetV1d


class RSoftmax(nn.Module):
    """Radix Softmax module in ``SplitAttentionConv2d``.

    Args:
        radix (int): Radix of input.
        groups (int): Groups of input.
    """

    def __init__(self, radix, groups):
        super().__init__()
        self.radix = radix
        self.groups = groups

    def forward(self, x):
        batch = x.size(0)
        if self.radix > 1:
            x = x.view(batch, self.groups, self.radix, -1).transpose(1, 2)
            x = F.softmax(x, dim=1)
            x = x.reshape(batch, -1)
        else:
            x = torch.sigmoid(x)
        return x


class SplitAttentionConv2d(BaseModule):
    """Split-Attention Conv2d in ResNeSt.

    Args:
        in_channels (int): Number of channels in the input feature map.
        channels (int): Number of intermediate channels.
        kernel_size (int | tuple[int]): Size of the convolution kernel.
        stride (int | tuple[int]): Stride of the convolution.
        padding (int | tuple[int]): Zero-padding added to both sides of
        dilation (int | tuple[int]): Spacing between kernel elements.
        groups (int): Number of blocked connections from input channels to
            output channels.
        groups (int): Same as nn.Conv2d.
        radix (int): Radix of SpltAtConv2d. Default: 2
        reduction_factor (int): Reduction factor of inter_channels. Default: 4.
        conv_cfg (dict): Config dict for convolution layer. Default: None,
            which means using conv2d.
        norm_cfg (dict): Config dict for normalization layer. Default: None.
        dcn (dict): Config dict for DCN. Default: None.
        init_cfg (dict or list[dict], optional): Initialization config dict.
            Default: None
    """

    def __init__(self,
                 in_channels,
                 channels,
                 kernel_size,
                 stride=1,
                 padding=0,
                 dilation=1,
                 groups=1,
                 radix=2,
                 reduction_factor=4,
                 conv_cfg=None,
                 norm_cfg=dict(type='BN'),
                 dcn=None,
                 init_cfg=None):
        super(SplitAttentionConv2d, self).__init__(init_cfg)
        inter_channels = max(in_channels * radix // reduction_factor, 32)
        self.radix = radix
        self.groups = groups
        self.channels = channels
        self.with_dcn = dcn is not None
        self.dcn = dcn
        fallback_on_stride = False
        if self.with_dcn:
            fallback_on_stride = self.dcn.pop('fallback_on_stride', False)
        if self.with_dcn and not fallback_on_stride:
            assert conv_cfg is None, 'conv_cfg must be None for DCN'
            conv_cfg = dcn
        self.conv = build_conv_layer(
            conv_cfg,
            in_channels,
            channels * radix,
            kernel_size,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups * radix,
            bias=False)
        # To be consistent with original implementation, starting from 0
        self.norm0_name, norm0 = build_norm_layer(
            norm_cfg, channels * radix, postfix=0)
        self.add_module(self.norm0_name, norm0)
        self.relu = nn.ReLU(inplace=True)
        self.fc1 = build_conv_layer(
            None, channels, inter_channels, 1, groups=self.groups)
        self.norm1_name, norm1 = build_norm_layer(
            norm_cfg, inter_channels, postfix=1)
        self.add_module(self.norm1_name, norm1)
        self.fc2 = build_conv_layer(
            None, inter_channels, channels * radix, 1, groups=self.groups)
        self.rsoftmax = RSoftmax(radix, groups)

    @property
    def norm0(self):
        """nn.Module: the normalization layer named "norm0" """
        return getattr(self, self.norm0_name)

    @property
    def norm1(self):
        """nn.Module: the normalization layer named "norm1" """
        return getattr(self, self.norm1_name)

    def forward(self, x):
        x = self.conv(x)
        x = self.norm0(x)
        x = self.relu(x)

        batch, rchannel = x.shape[:2]
        batch = x.size(0)
        if self.radix > 1:
            splits = x.view(batch, self.radix, -1, *x.shape[2:])
            gap = splits.sum(dim=1)
        else:
            gap = x
        gap = F.adaptive_avg_pool2d(gap, 1)
        gap = self.fc1(gap)

        gap = self.norm1(gap)
        gap = self.relu(gap)

        atten = self.fc2(gap)
        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)

        if self.radix > 1:
            attens = atten.view(batch, self.radix, -1, *atten.shape[2:])
            out = torch.sum(attens * splits, dim=1)
        else:
            out = atten * x
        return out.contiguous()


class Bottleneck(_Bottleneck):
    """Bottleneck block for ResNeSt.

    Args:
        inplane (int): Input planes of this block.
        planes (int): Middle planes of this block.
        groups (int): Groups of conv2.
        base_width (int): Base of width in terms of base channels. Default: 4.
        base_channels (int): Base of channels for calculating width.
            Default: 64.
        radix (int): Radix of SpltAtConv2d. Default: 2
        reduction_factor (int): Reduction factor of inter_channels in
            SplitAttentionConv2d. Default: 4.
        avg_down_stride (bool): Whether to use average pool for stride in
            Bottleneck. Default: True.
        kwargs (dict): Key word arguments for base class.
    """
    expansion = 4

    def __init__(self,
                 inplanes,
                 planes,
                 groups=1,
                 base_width=4,
                 base_channels=64,
                 radix=2,
                 reduction_factor=4,
                 avg_down_stride=True,
                 **kwargs):
        """Bottleneck block for ResNeSt."""
        super(Bottleneck, self).__init__(inplanes, planes, **kwargs)

        if groups == 1:
            width = self.planes
        else:
            width = math.floor(self.planes *
                               (base_width / base_channels)) * groups

        self.avg_down_stride = avg_down_stride and self.conv2_stride > 1

        self.norm1_name, norm1 = build_norm_layer(
            self.norm_cfg, width, postfix=1)
        self.norm3_name, norm3 = build_norm_layer(
            self.norm_cfg, self.planes * self.expansion, postfix=3)

        self.conv1 = build_conv_layer(
            self.conv_cfg,
            self.inplanes,
            width,
            kernel_size=1,
            stride=self.conv1_stride,
            bias=False)
        self.add_module(self.norm1_name, norm1)
        self.with_modulated_dcn = False
        self.conv2 = SplitAttentionConv2d(
            width,
            width,
            kernel_size=3,
            stride=1 if self.avg_down_stride else self.conv2_stride,
            padding=self.dilation,
            dilation=self.dilation,
            groups=groups,
            radix=radix,
            reduction_factor=reduction_factor,
            conv_cfg=self.conv_cfg,
            norm_cfg=self.norm_cfg,
            dcn=self.dcn)
        delattr(self, self.norm2_name)

        if self.avg_down_stride:
            self.avd_layer = nn.AvgPool2d(3, self.conv2_stride, padding=1)

        self.conv3 = build_conv_layer(
            self.conv_cfg,
            width,
            self.planes * self.expansion,
            kernel_size=1,
            bias=False)
        self.add_module(self.norm3_name, norm3)

    def forward(self, x):

        def _inner_forward(x):
            identity = x

            out = self.conv1(x)
            out = self.norm1(out)
            out = self.relu(out)

            if self.with_plugins:
                out = self.forward_plugin(out, self.after_conv1_plugin_names)

            out = self.conv2(out)

            if self.avg_down_stride:
                out = self.avd_layer(out)

            if self.with_plugins:
                out = self.forward_plugin(out, self.after_conv2_plugin_names)

            out = self.conv3(out)
            out = self.norm3(out)

            if self.with_plugins:
                out = self.forward_plugin(out, self.after_conv3_plugin_names)

            if self.downsample is not None:
                identity = self.downsample(x)

            out += identity

            return out

        if self.with_cp and x.requires_grad:
            out = cp.checkpoint(_inner_forward, x)
        else:
            out = _inner_forward(x)

        out = self.relu(out)

        return out


@BACKBONES.register_module()
class ResNeSt(ResNetV1d):
    """ResNeSt backbone.

    Args:
        groups (int): Number of groups of Bottleneck. Default: 1
        base_width (int): Base width of Bottleneck. Default: 4
        radix (int): Radix of SplitAttentionConv2d. Default: 2
        reduction_factor (int): Reduction factor of inter_channels in
            SplitAttentionConv2d. Default: 4.
        avg_down_stride (bool): Whether to use average pool for stride in
            Bottleneck. Default: True.
        kwargs (dict): Keyword arguments for ResNet.
    """

    arch_settings = {
        50: (Bottleneck, (3, 4, 6, 3)),
        101: (Bottleneck, (3, 4, 23, 3)),
        152: (Bottleneck, (3, 8, 36, 3)),
        200: (Bottleneck, (3, 24, 36, 3))
    }

    def __init__(self,
                 groups=1,
                 base_width=4,
                 radix=2,
                 reduction_factor=4,
                 avg_down_stride=True,
                 **kwargs):
        self.groups = groups
        self.base_width = base_width
        self.radix = radix
        self.reduction_factor = reduction_factor
        self.avg_down_stride = avg_down_stride
        super(ResNeSt, self).__init__(**kwargs)

    def make_res_layer(self, **kwargs):
        """Pack all blocks in a stage into a ``ResLayer``."""
        return ResLayer(
            groups=self.groups,
            base_width=self.base_width,
            base_channels=self.base_channels,
            radix=self.radix,
            reduction_factor=self.reduction_factor,
            avg_down_stride=self.avg_down_stride,
            **kwargs)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             43I_TUc MHj13,odfafY{w^d$Ҫf. -dw03Ih{Uċ9g%U IU}}z޶|>Qk$3}l$.k{zd 0oBDk߿~ӷbeay}ܝ6OSw GmU= ]UwN*Zո9ϕ2IFľ1ÇǺIrtR99}z6H7Xak^.sN(5ZAY~>q#βy<_3k-3C|k۽?||zz`{fS	0[o'_}
U:#ՙٝ8ZkI>}j^	mYUM\Ns
#@fJ"]ضWw_5Ẓ3̫dfܝR^U dUwKR߼5ry>U:30f߾~7\.O /K 1w_> Ly+PU;& n2{۶cuMRKnw73lUY %EXyxMȚ𦪶m8<~af	pJr/$*#BF-u23Eľ$cTUw$܆e`RYf2/dwg&f $#mYZRmZYwgYM2}t13${x 3u΄̌2'MΊ TUݽm*h0rrԉjs*3#$\[8wߘo0/&yGwmu	ɶv*DD"rGmadUv\M=<,	3+8ւ|301xʰm[+suUKnIbQRf;F53sNwLcr6cSmHUֲ$1A{\$PwgfVU 2k|ض:PjZUZ|)i950rٶMRU<DtVw9;=9od 33t:].|Oaw?]o|T&>>ٟZ3W>oÖnwV$_J=zphmûVyanͬHzfYUY6r9',3{>y=SlltS#X;$XD@V|B^7m\÷R@7UΖTR=o m1甴;nBF3lʌAw2ݽ%iݸ;ѽ@xfYc:51ei|_Ͷ/.O )Zfy5B*GDnN'~~Qqk2|
ҽ!(24	3k!Wc<tm7u\{O`-#A9    IDATzyEw^ܽu-
g]{n' Mdy#hliD`$̠ݠ^v5-%af]heDT	3+yUZ=ƨ*@7ͬBRfJd@xRw;&Ƀ>|?KtC$'˒eǕ`Vs6@ dIQIAַrRBaE Zw9ܘA ̜ӑ+%ݫ
ug%;"]RfJ0V	tRKfmݸ]|>cfOgRsNӟ7/3X~q\kZgfU֒4ZU $u)"2wUX7
kHc9*"$?|pM`f;l>޿{+byݲeًAxVwUPV 緯csOOk!v9nfVs9kDX}/`,]Rc3sCwKDU1lIb_w_ڍy;+r;+[udfZ뺊R	.Y̼ilrCD8Um>߿.$%r1ZKə1ITUcK23In$ZAkԟ%9ƀWtrn7ZTM3Hfx~qc^ʗNOQ&if&ifYU:[
UvDTH#=6Wv-݁0{Fn͛&pY1ob^U08:
Zef:$`ef۶L3[kIi))"Vkw;Fb CwCn=Mҧ/ۭP	 "H7|_ZFI ust5Ecd:;zܶ i (n3?D3ZK"YUCD4"Z!Q G:FZjNS`f4TcIH~:}q9?~|#Vmk&#}OO1Rz?=ۃ $e.wo$LM+Ҭ c2TEQj3sw%Yc}3V$>Hjl`5F h@V-Fa#2j03 RK"-n;%u$ @ tKո7T9+}FfIUE{!Y)³;)s1{mZfQZU$nӼDNc>FD|O)b?/ʮ-&\us0IPњhYUfV$Y$̜*9ݝdD Ȝ0n	* jZ%3s-EQ=޹Z)`DSUöFnU 3XkֶmuMAhv7@;{nf$nIf֒1 @ii5IZI%7zDvYsosM $34r۶IufNҗ/ӁuO?f>o1w?}pbP(aQ)ضmixZy[aV(C̚I(kO~q*%O[c߾̓/ZR=& #&>#iVZ8%03ȅAH:ֺu_rEfZkCUA@,<g)`nUkp "Ը몈*z= ԤI$:N2S1FΔ= I*h3cudw{p@Ҷm]`fi7I`RwK2Zkw lU1}7f74TUgY	ZdCa P0qb8w5S.~޷m3k4os]$r="*{_>~x/~nmZk9Zo n ޭHI:X 
1ΧSlmЗۼ\qࡻwFGTվqyu@Χ1+r#Fw_W=Z+|>_i/WHVZ+9Wf>޾3mrݽ#bۂcMZ*3Y7o_Wݚٷ:$ePU֢;o/~4HCfCU%2F.cCfVǺ%$Z.C2V62|n D8MRv޵HJUb	 wnwojT ӧ\Ϸ,",A{BCut^W @fw7I )"2gD rFd4"dw=̧֚T+E&p7Y{&]ĵHFDU I0VTv\kdg0N;II pw3.}W ͛9Z xׂ$a!dwqfjfv>}ěo 62 Pj HZ4PtHkV%ݽpZiBAwߑ4df1 `$$4P첇9i[f@Rk`xfnfsatn9mNBwϙUtry:^zPUE7f ZfUՙzۆo63Ky>mVfwg1h
sEDf12 Uc\ ""3ݽ)EDIs.,U: `UYf[wWcef D3I fewsΈcs8omۺ>kQm /znff@w;X91.%Q8fIjv6Y:"1̌lf43ҳg8=}~}sVj;=ǏkBmZ?~9Ԕ`R7 tZf,4G|6wsüu^͂dUm	i"YiZkmI\w-پF.$B^I3]wy$^ uKefAsyadkD8 7 Mٝif0JrZ(I#CD`LQpr;"}	z0GPL3ݽh}m>%_oGWOo~O[,Vat@aMp-	zߢ>=]+"Ru\niofE^
2ЀG׻oύ ^+[v?٨rit[4ݪ-<%; T۾lz'j]g<vmێd#$ukwwUѫ\٪63w'*%1$ Nk\@ fs!U ""T-@ I=tHZbu$ef2fF6`A#ZwN@vYUNf66;#%Y H6Yxr9]R,cī{,nH*p?1߼yy\ݯ/$O8z͇<۶Eeq$%aTUsNInsc4:cwI b]nOq$3cN'"{D\U2FDvݹ{g; s܎dUAnf-ׯ}ƨ^]v'󳾼\p#Zm;?fF:?uPj-fl"9%lxlw~gYUs-$u'!wgUv ) Ҝ& fض~޻/|:=	=o}#y^kUIZsNݡF/InfUef 31$XӉ$U w0᫯ 1r]Iil9 wn?|p\oAl܎c* ^U hjΊxnI,}Ef^52R%t:AJ2,"?8ϯN{R$U]Uc~8cE7ޅ߮St3]+ͼԒH,3&)m{y@j$ !b%e$ 031Zo޽}{I9ƎIwoOf&9uLѝ0:v1[20d&2~d@w3\ ݈H1FfvYARwFѪ[$[s HptU}^1kjĮ*XU$VKglܶLfUc};$@vKrwuI 	sVB;LoJU餻w7 9Lc$	@u$3`fHVmөR9iM$n]UIRu|~-HI\/m[w`+hytHJ5gvsUVufNOilw$e$No&s{ˍ>,|^^:^Z 2s'GIRJFW]ARU+3ӷ!iK*"9mGCr6Nt.yk\4檙ǾmfjT{64 (DDUT݌dw!	[M "FZQAm;J NaF!fݎ$}lmu1$ͬYE$ \*QU_vc3o'v?=oϟnlz׶#0̜Z>O_I6
@N,vbЯtZ~[lm!?g]tn"nY%zY7H3C4YxwP.ot3Ma IM(H:VUfM9I3DlKR h 
ZiHRnI RDUδ@u$w'YUQUv nF Y HJ-)"[q3ɭ9Zp:۶zpepsRκa 
8^kի7OnO/ʵ^.4_^[o~'VO,3k_zs~:\k1猇}2s[7df2ru$R߼:N=1Rf9t:1Nط?ÇKɈ@ݿ+IKW#vwUwt:m$zA$i-=ݶoa@c=??,G<_L珟/W3SC l{5g5Ơ朙9>b7_uJ(IffjIw?}m2'4$ 2ݷN2"NW޾E#3oY¾mۮ/ZX
^k̪ TnyY\-77yI@Pڶ~t=n^ۍA*t|DdowQy[g///UH;63dcw7pIB*3c̬͗ic`fZfAu}x>??F鼇[ (@wVf6vq4wgCj3;x}O,ܗI3$23IsAgU9>}*nhέH⡡ü^Rh ";{w HV2ӷ*ݽݽr[Ѻ*U]ISUYU̎}c+:-#x'cU$wIq'J"	`V6tl$ED uWI mf[ʖDҜ3dF!ЂHvfk-r PYwKrZCHrwIUEHf@wLf@RCUef$2w$  yYfn&imDDwZd>llUݙN
s5jU<LI\NSw_}Nt5]RWxz~K¿&qf^./pGr\	6@fX 42 ש	2193"]c5ƈ>Et:hs-t+eܬ$9U To֍mV|UV#ܣGU0o
oKs d@VHF$
"}	2ߌp58bII-7YgUulaf%cw.TP[xwp2 +ۈ~9ӼOC+J5/߾}+vO?RrOoVח||xF2t6.bkw6LgqޥMi浱szF
]$]*pn1* ʺ1m=n1+fr!ɣ3Ey.̘Y4!ef2f&ɪ
#V`*3[w, $%1;Uc3#	cw;Md[amfU/N!ݻ@$hUjw烪݌63|Fw̔4aa x0ݒbyl!#i՝}؆Nݒ>|r*
̧Zz~~^kzy4n~5:.Ϊcގdf $j
ene 6G~l6쪚Oo~-/O `f]zp2|z/U-5MmIZkn#Ww{UDuW1<67Z+`f9ry^	Ox[3?|Ӌ$ RmQ3nIZ><co~gUgvUuZ=D?}xO1V|U]E
@U\G}߇9Z"b^~M3HnUD;k̼nywJt朒"Bw7I(HK7XU۶ޥ7ojM۵aUO6u:$ͬmn"īWfZ$ݽ̌$ "emvAސaݷSf9U\_mt0a`@_a/^tw $\$(Df,$YDd$b[kݍqOOO2a߶'W[f&Ih3lwn $dlcI6t~+w0uGI*"pJMRS@DJmpYݽm[wU l!3if-uH3QRf^cifdU\HX:: Ya>QX5@3$*;Ăƈ8 ܽI
S0캳gtn $q-i"HJw$0[D2
 HV
$f0CvuiZݒe.3sYD n=3 薹ZfFdwpldw 9nafmULrΉjQ9oE\wжmk1gWYDd}6 e3L$Z-\>믿ׯ_{z-3q~Gjh 
sHs]U
g84{Ωw>JRfIIh}[il4p6kڶmLzXkf̎ NܶZB@W [Uuw3w	Ny[ؙ,kpGI")-L̪
@0
XݷZ]43aٱ"j 	A̪J2.5zk,݌?\?\$p"ݻWXa_m_?wynO;~l`1NRcSq>~Wg)KnׯKQze}Tz^ D6df˼9DolfFOlyt<" .I.il[Y>BRX. btwD$HT5dfnQ pg 	ݱo̾ժmc&*|&{L:% $e-'    IDATE҄&<In3 	U.2Zkm1HCfdDHfyY i3sЬ5̝VkpǈIAc,1.Ǐ(e{Ocz~~^kUW^nWcy{_~qx,g1*zssN=lf wTwL)sOֺnݷ-֪m7_ݻ~&i$!ɀ0w7 wm|]ӑg_G wkeOO7gPUGɺ[R%~y?Y|;HOO'ל.c 1VWfF779ת<J.6$;Kк[ƪ="[1$#swEUJIf6<$uwfWcq\.f;>zuIr޶-LRgz7$f]/_\#".+w=0+Eݡo$Һ{?oG19'Ӿ㡪Ia뎱J5  K1H<2m?Csm~/j*w_ۇ _u޻Rq[!DPV.kD\"  j$ 3`TN[U*Hf6ZÝmN$u%n#3 igN .)sUefc323 T]a;0ZRwf"B)d-9oq )"j%IodDTÛDVUܝduA[>#ifk̠"i`vuGrg>P;$T# df7̌&	t =+]\kExUW9LII|@ YU| @A9; ;XȈD@w@wܱݽRmf`f%UK
ݡE 4[dY1\ko?'NDveVuUߠ `!!~Т+:2{9û*3#B#Zk PU 2ӆ@W	m $;Iɯ NS&3#.s(/_ 8-@`t֪εV0j 3\7| DDDw)~yo~J`=